{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4904f206",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-05T21:39:50.407535Z",
     "iopub.status.busy": "2023-12-05T21:39:50.407195Z",
     "iopub.status.idle": "2023-12-05T21:39:52.033399Z",
     "shell.execute_reply": "2023-12-05T21:39:52.032528Z"
    },
    "papermill": {
     "duration": 1.638515,
     "end_time": "2023-12-05T21:39:52.035755",
     "exception": false,
     "start_time": "2023-12-05T21:39:50.397240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "import datetime \n",
    "from tqdm import tqdm\n",
    "\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from metric import score\n",
    "\n",
    "column_names = {\n",
    "    'series_id_column_name': 'series_id',\n",
    "    'time_column_name': 'step',\n",
    "    'event_column_name': 'event',\n",
    "    'score_column_name': 'score',\n",
    "}\n",
    "\n",
    "tolerances = {\n",
    "    'onset': [12, 36, 60, 90, 120, 150, 180, 240, 300, 360], \n",
    "    'wakeup': [12, 36, 60, 90, 120, 150, 180, 240, 300, 360]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beda5e76",
   "metadata": {
    "papermill": {
     "duration": 0.008708,
     "end_time": "2023-12-05T21:39:52.053661",
     "exception": false,
     "start_time": "2023-12-05T21:39:52.044953",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Importing data: approach 1 - more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a88b91d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T21:39:52.072690Z",
     "iopub.status.busy": "2023-12-05T21:39:52.072230Z",
     "iopub.status.idle": "2023-12-05T21:39:52.368177Z",
     "shell.execute_reply": "2023-12-05T21:39:52.367384Z"
    },
    "papermill": {
     "duration": 0.307943,
     "end_time": "2023-12-05T21:39:52.370363",
     "exception": false,
     "start_time": "2023-12-05T21:39:52.062420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dt_transforms = [\n",
    "    pl.col('timestamp').str.to_datetime(), \n",
    "    (pl.col('timestamp').str.to_datetime().dt.year()-2000).cast(pl.UInt8).alias('year'), \n",
    "    pl.col('timestamp').str.to_datetime().dt.month().cast(pl.UInt8).alias('month'),\n",
    "    pl.col('timestamp').str.to_datetime().dt.day().cast(pl.UInt8).alias('day'), \n",
    "    pl.col('timestamp').str.to_datetime().dt.hour().cast(pl.UInt8).alias('hour')\n",
    "]\n",
    "\n",
    "data_transforms = [\n",
    "    pl.col('anglez').cast(pl.Int16), # Casting anglez to 16 bit integer\n",
    "    (pl.col('enmo')*1000).cast(pl.UInt16), # Convert enmo to 16 bit uint\n",
    "]\n",
    "\n",
    "train_series = pl.scan_parquet('/kaggle/input/child-mind-institute-detect-sleep-states/train_series.parquet').with_columns(\n",
    "    dt_transforms + data_transforms\n",
    "    )\n",
    "\n",
    "train_events = pl.read_csv('/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv').with_columns(\n",
    "    dt_transforms\n",
    "    ).drop_nulls()\n",
    "\n",
    "test_series = pl.scan_parquet('/kaggle/input/child-mind-institute-detect-sleep-states/test_series.parquet').with_columns(\n",
    "    dt_transforms + data_transforms\n",
    "    )\n",
    "\n",
    "# Removing null events and nights with mismatched counts from series_events\n",
    "mismatches = train_events.drop_nulls().group_by(['series_id', 'night']).agg([\n",
    "    ((pl.col('event') == 'onset').sum() == (pl.col('event') == 'wakeup').sum()).alias('balanced')\n",
    "    ]).sort(by=['series_id', 'night']).filter(~pl.col('balanced'))\n",
    "\n",
    "for mm in mismatches.to_numpy(): \n",
    "    train_events = train_events.filter(~((pl.col('series_id') == mm[0]) & (pl.col('night') == mm[1])))\n",
    "\n",
    "# Getting series ids as a list for convenience\n",
    "series_ids = train_events['series_id'].unique(maintain_order=True).to_list()\n",
    "\n",
    "# Updating train_series to only keep these series ids\n",
    "train_series = train_series.filter(pl.col('series_id').is_in(series_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b176bc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T21:39:52.407331Z",
     "iopub.status.busy": "2023-12-05T21:39:52.407009Z",
     "iopub.status.idle": "2023-12-05T21:39:52.422350Z",
     "shell.execute_reply": "2023-12-05T21:39:52.421488Z"
    },
    "papermill": {
     "duration": 0.027011,
     "end_time": "2023-12-05T21:39:52.424186",
     "exception": false,
     "start_time": "2023-12-05T21:39:52.397175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features, feature_cols = [pl.col('hour')], ['hour']\n",
    "\n",
    "for mins in [5, 30, 60*2, 60*8] :\n",
    "    \n",
    "    for var in ['enmo', 'anglez'] :\n",
    "        \n",
    "        features += [\n",
    "            pl.col(var).rolling_mean(12 * mins, center=True, min_periods=1).abs().cast(pl.UInt16).alias(f'{var}_{mins}m_mean'),\n",
    "            pl.col(var).rolling_max(12 * mins, center=True, min_periods=1).abs().cast(pl.UInt16).alias(f'{var}_{mins}m_max'),\n",
    "            pl.col(var).rolling_std(12 * mins, center=True, min_periods=1).abs().cast(pl.UInt16).alias(f'{var}_{mins}m_std')\n",
    "        ]\n",
    "\n",
    "        feature_cols += [ \n",
    "            f'{var}_{mins}m_mean', f'{var}_{mins}m_max', f'{var}_{mins}m_std'\n",
    "        ]\n",
    "\n",
    "        # Getting first variations\n",
    "        features += [\n",
    "            (pl.col(var).diff().abs().rolling_mean(12 * mins, center=True, min_periods=1)*10).abs().cast(pl.UInt32).alias(f'{var}_1v_{mins}m_mean'),\n",
    "            (pl.col(var).diff().abs().rolling_max(12 * mins, center=True, min_periods=1)*10).abs().cast(pl.UInt32).alias(f'{var}_1v_{mins}m_max'),\n",
    "            (pl.col(var).diff().abs().rolling_std(12 * mins, center=True, min_periods=1)*10).abs().cast(pl.UInt32).alias(f'{var}_1v_{mins}m_std')\n",
    "        ]\n",
    "\n",
    "        feature_cols += [ \n",
    "            f'{var}_1v_{mins}m_mean', f'{var}_1v_{mins}m_max', f'{var}_1v_{mins}m_std'\n",
    "        ]\n",
    "\n",
    "id_cols = ['series_id', 'step', 'timestamp']\n",
    "\n",
    "train_series = train_series.with_columns(\n",
    "    features\n",
    ").select(id_cols + feature_cols)\n",
    "\n",
    "test_series = test_series.with_columns(\n",
    "    features\n",
    ").select(id_cols + feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ae8d302",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T21:39:52.443100Z",
     "iopub.status.busy": "2023-12-05T21:39:52.442800Z",
     "iopub.status.idle": "2023-12-05T21:39:52.452443Z",
     "shell.execute_reply": "2023-12-05T21:39:52.451680Z"
    },
    "papermill": {
     "duration": 0.021233,
     "end_time": "2023-12-05T21:39:52.454369",
     "exception": false,
     "start_time": "2023-12-05T21:39:52.433136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_train_dataset(train_data, train_events, drop_nulls=False) :\n",
    "    \n",
    "    series_ids = train_data['series_id'].unique(maintain_order=True).to_list()\n",
    "    X, y = pl.DataFrame(), pl.DataFrame()\n",
    "    for idx in tqdm(series_ids) : \n",
    "        \n",
    "        # Normalizing sample features\n",
    "        sample = train_data.filter(pl.col('series_id')==idx).with_columns(\n",
    "            [(pl.col(col) / pl.col(col).std()).cast(pl.Float32) for col in feature_cols if col != 'hour']\n",
    "        )\n",
    "        \n",
    "        events = train_events.filter(pl.col('series_id')==idx)\n",
    "        \n",
    "        if drop_nulls : \n",
    "            # Removing datapoints on dates where no data was recorded\n",
    "            sample = sample.filter(\n",
    "                pl.col('timestamp').dt.date().is_in(events['timestamp'].dt.date())\n",
    "            )\n",
    "        \n",
    "        X = X.vstack(sample[id_cols + feature_cols])\n",
    "\n",
    "        onsets = events.filter((pl.col('event') == 'onset') & (pl.col('step') != None))['step'].to_list()\n",
    "        wakeups = events.filter((pl.col('event') == 'wakeup') & (pl.col('step') != None))['step'].to_list()\n",
    "\n",
    "        # NOTE: This will break if there are event series without any recorded onsets or wakeups\n",
    "        y = y.vstack(sample.with_columns(\n",
    "            sum([(onset <= pl.col('step')) & (pl.col('step') <= wakeup) for onset, wakeup in zip(onsets, wakeups)]).cast(pl.Boolean).alias('asleep')\n",
    "            ).select('asleep')\n",
    "            )\n",
    "    \n",
    "    y = y.to_numpy().ravel()\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c24050b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T21:39:52.473409Z",
     "iopub.status.busy": "2023-12-05T21:39:52.473164Z",
     "iopub.status.idle": "2023-12-05T21:39:52.486178Z",
     "shell.execute_reply": "2023-12-05T21:39:52.485429Z"
    },
    "papermill": {
     "duration": 0.024838,
     "end_time": "2023-12-05T21:39:52.488072",
     "exception": false,
     "start_time": "2023-12-05T21:39:52.463234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_events(series, classifier) :\n",
    "    '''\n",
    "    Takes a time series and a classifier and returns a formatted submission dataframe.\n",
    "    '''\n",
    "    \n",
    "    series_ids = series['series_id'].unique(maintain_order=True).to_list()\n",
    "    events = pl.DataFrame(schema={'series_id':str, 'step':int, 'event':str, 'score':float})\n",
    "\n",
    "    for idx in tqdm(series_ids) : \n",
    "\n",
    "        # Collecting sample and normalizing features\n",
    "        scale_cols = [col for col in feature_cols if (col != 'hour') & (series[col].std() !=0)]\n",
    "        X = series.filter(pl.col('series_id') == idx).select(id_cols + feature_cols).with_columns(\n",
    "            [(pl.col(col) / series[col].std()).cast(pl.Float32) for col in scale_cols]\n",
    "        )\n",
    "\n",
    "        # Applying classifier to get predictions and scores\n",
    "        preds, probs = classifier.predict(X[feature_cols]), classifier.predict_proba(X[feature_cols])[:, 1]\n",
    "\n",
    "        #NOTE: Considered using rolling max to get sleep periods excluding <30 min interruptions, but ended up decreasing performance\n",
    "        X = X.with_columns(\n",
    "            pl.lit(preds).cast(pl.Int8).alias('prediction'), \n",
    "            pl.lit(probs).alias('probability')\n",
    "                        )\n",
    "        \n",
    "        # Getting predicted onset and wakeup time steps\n",
    "        pred_onsets = X.filter(X['prediction'].diff() > 0)['step'].to_list()\n",
    "        pred_wakeups = X.filter(X['prediction'].diff() < 0)['step'].to_list()\n",
    "        \n",
    "        if len(pred_onsets) > 0 : \n",
    "            \n",
    "            # Ensuring all predicted sleep periods begin and end\n",
    "            if min(pred_wakeups) < min(pred_onsets) : \n",
    "                pred_wakeups = pred_wakeups[1:]\n",
    "\n",
    "            if max(pred_onsets) > max(pred_wakeups) :\n",
    "                pred_onsets = pred_onsets[:-1]\n",
    "\n",
    "            # Keeping sleep periods longer than 30 minutes\n",
    "            sleep_periods = [(onset, wakeup) for onset, wakeup in zip(pred_onsets, pred_wakeups) if wakeup - onset >= 12 * 30]\n",
    "\n",
    "            for onset, wakeup in sleep_periods :\n",
    "                # Scoring using mean probability over period\n",
    "                score = X.filter((pl.col('step') >= onset) & (pl.col('step') <= wakeup))['probability'].mean()\n",
    "\n",
    "                # Adding sleep event to dataframe\n",
    "                events = events.vstack(pl.DataFrame().with_columns(\n",
    "                    pl.Series([idx, idx]).alias('series_id'), \n",
    "                    pl.Series([onset, wakeup]).alias('step'),\n",
    "                    pl.Series(['onset', 'wakeup']).alias('event'),\n",
    "                    pl.Series([score, score]).alias('score')\n",
    "                ))\n",
    "\n",
    "    # Adding row id column\n",
    "    events = events.to_pandas().reset_index().rename(columns={'index':'row_id'})\n",
    "\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a3d0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting datapoints at every 5 minutes\n",
    "train_data = train_series.filter(pl.col('series_id').is_in(series_ids)).take_every(12 * 5).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b7ee12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 269/269 [00:05<00:00, 53.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# Creating train dataset\n",
    "X_train, y_train = make_train_dataset(train_data, train_events)\n",
    "X_train = X_train[feature_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091785af",
   "metadata": {},
   "source": [
    "## Approach 2 - less features on preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df1f727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from here: https://www.kaggle.com/datasets/carlmcbrideellis/zzzs-lightweight-training-dataset-target\n",
    "train = pd.read_parquet(\"/kaggle/input/zzzs-make-small-starter-datasets-target/Zzzs_train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b446a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(df):\n",
    "    # parse the timestamp and create an \"hour\" feature\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp']).apply(lambda t: t.tz_localize(None))\n",
    "    df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
    "    \n",
    "    periods = 20\n",
    "    df[\"anglez\"] = abs(df[\"anglez\"])\n",
    "    df[\"anglez_diff\"] = df.groupby('series_id')['anglez'].diff(periods=periods).fillna(method=\"bfill\").astype('float16')\n",
    "    df[\"enmo_diff\"] = df.groupby('series_id')['enmo'].diff(periods=periods).fillna(method=\"bfill\").astype('float16')\n",
    "    df[\"anglez_rolling_mean\"] = df[\"anglez\"].rolling(periods,center=True).mean().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    df[\"enmo_rolling_mean\"] = df[\"enmo\"].rolling(periods,center=True).mean().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    df[\"anglez_rolling_max\"] = df[\"anglez\"].rolling(periods,center=True).max().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    df[\"enmo_rolling_max\"] = df[\"enmo\"].rolling(periods,center=True).max().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    df[\"anglez_rolling_std\"] = df[\"anglez\"].rolling(periods,center=True).std().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    df[\"enmo_rolling_std\"] = df[\"enmo\"].rolling(periods,center=True).std().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    df[\"anglez_diff_rolling_mean\"] = df[\"anglez_diff\"].rolling(periods,center=True).mean().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    df[\"enmo_diff_rolling_mean\"] = df[\"enmo_diff\"].rolling(periods,center=True).mean().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    df[\"anglez_diff_rolling_max\"] = df[\"anglez_diff\"].rolling(periods,center=True).max().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    df[\"enmo_diff_rolling_max\"] = df[\"enmo_diff\"].rolling(periods,center=True).max().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    \n",
    "    return df\n",
    "\n",
    "features_columns = [\n",
    "    \"hour\",\n",
    "    \"anglez\",\n",
    "    \"anglez_rolling_mean\",\n",
    "    \"anglez_rolling_max\",\n",
    "    \"anglez_rolling_std\",\n",
    "    \"anglez_diff\",\n",
    "    \"anglez_diff_rolling_mean\",\n",
    "    \"anglez_diff_rolling_max\",\n",
    "    \"enmo\",\n",
    "    \"enmo_rolling_mean\",\n",
    "    \"enmo_rolling_max\",\n",
    "    \"enmo_rolling_std\",\n",
    "    \"enmo_diff\",\n",
    "    \"enmo_diff_rolling_mean\",\n",
    "    \"enmo_diff_rolling_max\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bae30da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train   = make_features(train)\n",
    "\n",
    "X_train = train[features_columns]\n",
    "y_train = train[\"awake\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e736de84",
   "metadata": {
    "papermill": {
     "duration": 0.008667,
     "end_time": "2023-12-05T21:39:52.505527",
     "exception": false,
     "start_time": "2023-12-05T21:39:52.496860",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a26cc92",
   "metadata": {},
   "source": [
    "## GXBoost | RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bebd22b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T21:44:01.904749Z",
     "iopub.status.busy": "2023-12-05T21:44:01.904424Z",
     "iopub.status.idle": "2023-12-05T21:44:03.030591Z",
     "shell.execute_reply": "2023-12-05T21:44:03.029766Z"
    },
    "papermill": {
     "duration": 1.142232,
     "end_time": "2023-12-05T21:44:03.032911",
     "exception": false,
     "start_time": "2023-12-05T21:44:01.890679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51cc684a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T21:44:03.059988Z",
     "iopub.status.busy": "2023-12-05T21:44:03.059367Z",
     "iopub.status.idle": "2023-12-05T21:44:03.063532Z",
     "shell.execute_reply": "2023-12-05T21:44:03.062668Z"
    },
    "papermill": {
     "duration": 0.019405,
     "end_time": "2023-12-05T21:44:03.065288",
     "exception": false,
     "start_time": "2023-12-05T21:44:03.045883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = dict()\n",
    "params[\"device\"] = \"cuda\"\n",
    "params[\"tree_method\"] = \"hist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e0b2326",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T21:44:03.091592Z",
     "iopub.status.busy": "2023-12-05T21:44:03.091311Z",
     "iopub.status.idle": "2023-12-05T21:44:03.095421Z",
     "shell.execute_reply": "2023-12-05T21:44:03.094670Z"
    },
    "papermill": {
     "duration": 0.019328,
     "end_time": "2023-12-05T21:44:03.097305",
     "exception": false,
     "start_time": "2023-12-05T21:44:03.077977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier(tree_method=\"hist\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b61c3e6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T21:44:03.168411Z",
     "iopub.status.busy": "2023-12-05T21:44:03.167590Z",
     "iopub.status.idle": "2023-12-05T21:44:37.370453Z",
     "shell.execute_reply": "2023-12-05T21:44:37.369517Z"
    },
    "papermill": {
     "duration": 34.232726,
     "end_time": "2023-12-05T21:44:37.386384",
     "exception": false,
     "start_time": "2023-12-05T21:44:03.153658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:44:07] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"device\" } are not used.\n",
      "\n",
      "CPU times: user 2min, sys: 1.22 s, total: 2min 2s\n",
      "Wall time: 34.2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device='cuda', early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, ...)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5c54b4",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb2f145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f1de66",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Sequential([ # Le minimum\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ca6423",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd7a335",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split = 0.3, # not good, but otherwise even worse\n",
    "    batch_size = 128,\n",
    "    callbacks =[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min',patience=2, verbose=1),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\"best_model.h5\", monitor= 'val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "        ],\n",
    "    epochs = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21637ec",
   "metadata": {
    "papermill": {
     "duration": 0.013842,
     "end_time": "2023-12-05T22:55:52.318258",
     "exception": false,
     "start_time": "2023-12-05T22:55:52.304416",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Applying to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304e8079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b041c867",
   "metadata": {},
   "source": [
    "### Approach with more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0b6c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 49.70it/s]\n"
     ]
    }
   ],
   "source": [
    "submission = get_events(test_series.collect(), clf) # approach with more features\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76ee621",
   "metadata": {},
   "source": [
    "### Approach with less features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d167572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f191954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event(df):\n",
    "    lstCV = zip(df.series_id, df.smooth)\n",
    "    lstPOI = []\n",
    "    for (c, v), g in groupby(lstCV, lambda cv: \n",
    "                            (cv[0], cv[1]!=0 and not pd.isnull(cv[1]))):\n",
    "        llg = sum(1 for item in g)\n",
    "        if v is False: \n",
    "            lstPOI.extend([0]*llg)\n",
    "        else: \n",
    "            lstPOI.extend(['onset']+(llg-2)*[0]+['wakeup'] if llg > 1 else [0])\n",
    "    return lstPOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59e23ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test  = pd.read_parquet(\"/kaggle/input/child-mind-institute-detect-sleep-states/test_series.parquet\")\n",
    "\n",
    "test  = make_features(test)\n",
    "\n",
    "X_test = test[features]\n",
    "\n",
    "test[\"awake\"] = clf.predict(X_test)[:,0]\n",
    "test[\"not_awake\"] = 1 - clf.predict(X_test)[:,0]\n",
    "\n",
    "smoothing_length = 2*230\n",
    "test[\"score\"]  = test[\"awake\"].rolling(smoothing_length,center=True).mean().fillna(method=\"bfill\").fillna(method=\"ffill\")\n",
    "test[\"smooth\"] = test[\"not_awake\"].rolling(smoothing_length,center=True).mean().fillna(method=\"bfill\").fillna(method=\"ffill\")\n",
    "# re-binarize\n",
    "test[\"smooth\"] = test[\"smooth\"].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ec4181",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"event\"] = get_event(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89e740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = test.loc[test[\"event\"] != 0][[\"series_id\",\"step\",\"event\",\"score\"]].copy().reset_index(drop=True).reset_index(names=\"row_id\")\n",
    "sample_submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 6589269,
     "sourceId": 53666,
     "sourceType": "competition"
    },
    {
     "datasetId": 4032615,
     "sourceId": 7013734,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 151169343,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30558,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4567.95787,
   "end_time": "2023-12-05T22:55:54.947320",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-05T21:39:46.989450",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
